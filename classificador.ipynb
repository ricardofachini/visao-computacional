{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:39:27.885685Z",
     "start_time": "2024-12-09T15:39:27.882351Z"
    }
   },
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "496952c48e58af2d",
   "metadata": {},
   "source": [
    "Carregar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d1ea2c088f6639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:39:33.753705Z",
     "start_time": "2024-12-09T15:39:31.746818Z"
    }
   },
   "source": [
    "im = cv2.imread(\"./teste.jpg\")\n",
    "cv2.imshow(\"win\", im)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after the key press\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[12/09 12:39:33 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardofachini/miniconda3/envs/visao-computacional/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647380992/work/aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:31:35.740479Z",
     "start_time": "2024-12-09T15:31:34.624276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow(\"w\", out.get_image()[:, :, ::-1])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after the key press\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "135f40555767d8b9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "f94dfb58ea69c697",
   "metadata": {},
   "source": [
    "Carregar dataset de car-damage"
   ]
  },
  {
   "cell_type": "code",
   "id": "881fd16c444db522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:38:58.084043Z",
     "start_time": "2024-12-09T15:38:58.077424Z"
    }
   },
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# !curl -L \"https://universe.roboflow.com/ds/5sncDNZAeT?key=lgL2BuIUSz\" > roboflow.zip; unzip roboflow.zip -d datasets/car-damage-s4; rm roboflow.zip\n",
    "# !curl -L \"https://universe.roboflow.com/ds/R0WssxzPHH?key=DrYHDd0r3w\" > roboflow.zip; unzip roboflow.zip -d datasets/severity; rm roboflow.zip\n",
    "\n",
    "\n",
    "# Replace with paths to your dataset\n",
    "register_coco_instances(\"car-damage-v8-train\", {}, \"datasets/car-damage-v8/train/_annotations.coco.json\", \"datasets/car-damage-v8/train\")\n",
    "register_coco_instances(\"car-damage-v8-test\", {}, \"datasets/car-damage-v8/valid/_annotations.coco.json\", \"datasets/car-damage-v8/valid\")\n",
    "# register_coco_instances(\"car-damage-s4-train\", {}, \"datasets/car-damage-s4/train/_annotations.coco.json\", \"datasets/car-damage-s4/train\")\n",
    "# register_coco_instances(\"car-damage-s4-test\", {}, \"datasets/car-damage-s4/test/_annotations.coco.json\", \"datasets/car-damage-s4/test\")\n",
    "# register_coco_instances(\"severity-train\", {}, \"datasets/severity/train/_annotations.coco.json\", \"datasets/severity/train\")\n",
    "# register_coco_instances(\"severity-test\", {}, \"datasets/severity/test/_annotations.coco.json\", \"datasets/severity/test\")\n",
    "# register_coco_instances(\"severity-val\", {}, \"datasets/severity/valid/_annotations.coco.json\", \"datasets/severity/valid\")\n",
    "\n",
    "# Verify if the dataset is correctly registered\n",
    "my_dataset_metadata = MetadataCatalog.get(\"car-damage-v8-train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"car-damage-v8-train\")\n",
    "\n",
    "print(len(my_dataset_metadata.thing_classes))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "3b1247a675a2db1b",
   "metadata": {},
   "source": [
    "Printar resultados"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:39:21.895140Z",
     "start_time": "2024-12-09T15:39:19.060258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# Get the dataset metadata and dataset dicts\n",
    "# dataset_dicts = DatasetCatalog.get(\"severity-test\")\n",
    "# metadata = MetadataCatalog.get(\"severity-test\")\n",
    "\n",
    "# Plot a few random images from the dataset\n",
    "for d in random.sample(dataset_dicts, 3):  # Change the number to print more or fewer images\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "\n",
    "    # Create a visualizer and draw annotations (bounding boxes, etc.)\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_metadata, scale=0.8)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "\n",
    "    # Display the image with matplotlib\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cv2.imshow(\"w\", vis.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    # Close the window after the key press\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "c4929269dde093dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Selecionar modelo e treinar dataset de treino",
   "id": "3cb414bf8564639a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:41:07.527898Z",
     "start_time": "2024-12-09T15:39:37.994185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")) #\n",
    "cfg.DATASETS.TRAIN = (\"car-damage-v8-train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 300 #2000\n",
    "cfg.SOLVER.STEPS = (3000, 4000)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ],
   "id": "811e6c82620126a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[12/09 12:39:38 d2.engine.defaults]: \u001B[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[12/09 12:39:38 d2.data.datasets.coco]: \u001B[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001B[32m[12/09 12:39:38 d2.data.datasets.coco]: \u001B[0mLoaded 149 images in COCO format from datasets/car-damage-v8/train/_annotations.coco.json\n",
      "\u001B[32m[12/09 12:39:38 d2.data.build]: \u001B[0mRemoved 1 images with no usable annotations. 148 images left.\n",
      "\u001B[32m[12/09 12:39:38 d2.data.build]: \u001B[0mDistribution of instances among all 2 categories:\n",
      "\u001B[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "| car-damage | 0            |   object   | 334          |\n",
      "|            |              |            |              |\n",
      "|   total    | 334          |            |              |\u001B[0m\n",
      "\u001B[32m[12/09 12:39:38 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[12/09 12:39:38 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[12/09 12:39:38 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[12/09 12:39:38 d2.data.common]: \u001B[0mSerializing 148 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[12/09 12:39:38 d2.data.common]: \u001B[0mSerialized dataset takes 0.14 MiB\n",
      "\u001B[32m[12/09 12:39:38 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=2\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[12/09 12:39:38 d2.solver.build]: \u001B[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001B[32m[12/09 12:39:38 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001B[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.mask_head.predictor.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[12/09 12:39:38 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n",
      "\u001B[32m[12/09 12:39:44 d2.utils.events]: \u001B[0m eta: 0:01:16  iter: 19  total_loss: 2.243  loss_cls: 1.153  loss_box_reg: 0.3044  loss_mask: 0.6931  loss_rpn_cls: 0.05411  loss_rpn_loc: 0.01664    time: 0.2763  last_time: 0.2565  data_time: 0.0083  last_data_time: 0.0023   lr: 1.6068e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:39:50 d2.utils.events]: \u001B[0m eta: 0:01:09  iter: 39  total_loss: 1.963  loss_cls: 0.7775  loss_box_reg: 0.3288  loss_mask: 0.6883  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.02477    time: 0.2726  last_time: 0.2290  data_time: 0.0024  last_data_time: 0.0023   lr: 3.2718e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:39:55 d2.utils.events]: \u001B[0m eta: 0:01:04  iter: 59  total_loss: 1.493  loss_cls: 0.4476  loss_box_reg: 0.2764  loss_mask: 0.6786  loss_rpn_cls: 0.07568  loss_rpn_loc: 0.01787    time: 0.2761  last_time: 0.2990  data_time: 0.0026  last_data_time: 0.0028   lr: 4.9367e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:40:01 d2.utils.events]: \u001B[0m eta: 0:01:00  iter: 79  total_loss: 1.429  loss_cls: 0.3307  loss_box_reg: 0.3077  loss_mask: 0.6624  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.01811    time: 0.2787  last_time: 0.3069  data_time: 0.0026  last_data_time: 0.0025   lr: 6.6017e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:40:07 d2.utils.events]: \u001B[0m eta: 0:00:55  iter: 99  total_loss: 1.272  loss_cls: 0.2972  loss_box_reg: 0.2674  loss_mask: 0.6443  loss_rpn_cls: 0.05208  loss_rpn_loc: 0.01533    time: 0.2813  last_time: 0.2617  data_time: 0.0027  last_data_time: 0.0027   lr: 8.2668e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:40:13 d2.utils.events]: \u001B[0m eta: 0:00:50  iter: 119  total_loss: 1.33  loss_cls: 0.3052  loss_box_reg: 0.3117  loss_mask: 0.6299  loss_rpn_cls: 0.04285  loss_rpn_loc: 0.01444    time: 0.2839  last_time: 0.2222  data_time: 0.0026  last_data_time: 0.0024   lr: 9.9318e-05  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:40:18 d2.utils.events]: \u001B[0m eta: 0:00:44  iter: 139  total_loss: 1.313  loss_cls: 0.2988  loss_box_reg: 0.3541  loss_mask: 0.5969  loss_rpn_cls: 0.05084  loss_rpn_loc: 0.01626    time: 0.2838  last_time: 0.2805  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00011597  max_mem: 1940M\n",
      "\u001B[32m[12/09 12:40:24 d2.utils.events]: \u001B[0m eta: 0:00:39  iter: 159  total_loss: 1.15  loss_cls: 0.24  loss_box_reg: 0.2856  loss_mask: 0.5592  loss_rpn_cls: 0.02966  loss_rpn_loc: 0.01133    time: 0.2851  last_time: 0.3025  data_time: 0.0026  last_data_time: 0.0027   lr: 0.00013262  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:30 d2.utils.events]: \u001B[0m eta: 0:00:33  iter: 179  total_loss: 1.132  loss_cls: 0.2696  loss_box_reg: 0.3238  loss_mask: 0.53  loss_rpn_cls: 0.0512  loss_rpn_loc: 0.01781    time: 0.2836  last_time: 0.2897  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00014927  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:36 d2.utils.events]: \u001B[0m eta: 0:00:28  iter: 199  total_loss: 1.254  loss_cls: 0.2752  loss_box_reg: 0.3704  loss_mask: 0.5256  loss_rpn_cls: 0.03814  loss_rpn_loc: 0.02217    time: 0.2887  last_time: 0.3969  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00016592  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:42 d2.utils.events]: \u001B[0m eta: 0:00:22  iter: 219  total_loss: 0.9752  loss_cls: 0.2142  loss_box_reg: 0.2445  loss_mask: 0.4726  loss_rpn_cls: 0.04333  loss_rpn_loc: 0.0107    time: 0.2877  last_time: 0.2522  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00018257  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:47 d2.utils.events]: \u001B[0m eta: 0:00:16  iter: 239  total_loss: 1.165  loss_cls: 0.2679  loss_box_reg: 0.3489  loss_mask: 0.4692  loss_rpn_cls: 0.0292  loss_rpn_loc: 0.01587    time: 0.2865  last_time: 0.2772  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00019922  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:53 d2.utils.events]: \u001B[0m eta: 0:00:11  iter: 259  total_loss: 1.093  loss_cls: 0.2423  loss_box_reg: 0.3422  loss_mask: 0.435  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.01974    time: 0.2872  last_time: 0.2593  data_time: 0.0027  last_data_time: 0.0024   lr: 0.00021587  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:40:59 d2.utils.events]: \u001B[0m eta: 0:00:05  iter: 279  total_loss: 0.9433  loss_cls: 0.2089  loss_box_reg: 0.2806  loss_mask: 0.405  loss_rpn_cls: 0.03309  loss_rpn_loc: 0.01084    time: 0.2876  last_time: 0.2561  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00023252  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:41:07 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 299  total_loss: 1.09  loss_cls: 0.1974  loss_box_reg: 0.2681  loss_mask: 0.4254  loss_rpn_cls: 0.03063  loss_rpn_loc: 0.01474    time: 0.2896  last_time: 0.3157  data_time: 0.0027  last_data_time: 0.0025   lr: 0.00024917  max_mem: 1943M\n",
      "\u001B[32m[12/09 12:41:07 d2.engine.hooks]: \u001B[0mOverall training speed: 298 iterations in 0:01:26 (0.2896 s / it)\n",
      "\u001B[32m[12/09 12:41:07 d2.engine.hooks]: \u001B[0mTotal training time: 0:01:27 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ],
   "id": "c3bbc5d5a11193ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate",
   "id": "25deb84e3ee29025"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:41:36.083094Z",
     "start_time": "2024-12-09T15:41:35.456858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "# Configurações para o modelo treinado\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # Caminho para o modelo salvo\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3  # Ajuste o threshold de detecção, se necessário\n",
    "predictor = DefaultPredictor(cfg)\n"
   ],
   "id": "3bbdd97a0787574b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[12/09 12:41:35 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardofachini/miniconda3/envs/visao-computacional/lib/python3.9/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualizar resultado",
   "id": "f013c7569ce2619f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:41:52.158251Z",
     "start_time": "2024-12-09T15:41:39.409007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=my_dataset_metadata,\n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    print(outputs[\"instances\"].pred_classes)  # Classes preditas\n",
    "    print(outputs[\"instances\"].pred_boxes)\n",
    "    cv2.imshow(\"w\", out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Close the window after the key press\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "6c96a5dd46986f47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Boxes(tensor([[106.1708,  19.2041, 348.0602, 191.4880],\n",
      "        [157.7554,  52.6061, 304.0989, 248.8642],\n",
      "        [ 46.7163,   1.3430, 370.5620, 322.3849],\n",
      "        [ 56.7064,  75.1521, 175.7081, 250.3241],\n",
      "        [168.0660,  33.1937, 314.6277, 171.0528],\n",
      "        [ 51.6978,  52.9554, 268.5035, 231.1189],\n",
      "        [249.8474, 215.3847, 314.5869, 312.8590],\n",
      "        [ 84.1882,  96.1413, 154.4855, 224.4031],\n",
      "        [ 30.4920,  86.2998, 147.8165, 291.0134],\n",
      "        [ 60.8694,  29.2553, 158.2602, 137.3021],\n",
      "        [  5.9359,  33.0697, 191.3265, 308.7455]], device='cuda:0'))\n",
      "tensor([1], device='cuda:0')\n",
      "Boxes(tensor([[164.1096,  62.0236, 411.2791, 220.0856]], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Boxes(tensor([[177.7712,  76.8734, 331.8645, 363.7521],\n",
      "        [184.2011, 194.4961, 282.4620, 361.8541],\n",
      "        [191.3517,  28.5196, 315.0508, 251.7374],\n",
      "        [ 13.3866,  14.7259, 375.9769, 396.6322],\n",
      "        [164.3337, 186.9096, 327.7886, 317.6278],\n",
      "        [191.4981, 218.2191, 332.6241, 383.5671],\n",
      "        [182.1192,  62.5214, 272.6154, 274.8405],\n",
      "        [132.1187,  95.7769, 339.0186, 263.3371],\n",
      "        [162.4408,  59.1404, 346.8391, 202.8881],\n",
      "        [ 23.8309,   7.2514, 171.3642, 124.3096]], device='cuda:0'))\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testar uma imagem qualquer",
   "id": "b06a20822c3b7b3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
